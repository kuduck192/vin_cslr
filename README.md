# Vietnamese Continuous Sign Language Recognition - VinBigdata Computer Vision Project

Real-time sign language recognition system with Text-to-Speech output.

## ðŸ“ Project Structure

```
project/
â”œâ”€â”€ main.py           # Main application with webcam UI
â”œâ”€â”€ slr/
â”‚   â””â”€â”€ __init__.py   # Exports APIs
â”‚   â””â”€â”€ slr.py        # Sign Language Recognition module
â”œâ”€â”€ tts/
â”‚   â””â”€â”€ __init__.py   # Exports APIs
â”‚   â””â”€â”€ slr.py        # Text-to-Speech module
â”œâ”€â”€ requirements.txt  # Dependencies
â””â”€â”€ README.md         # This file
```

## ðŸš€ Quick Start

### 1. Create virtual env
```bash
python -m venv .venv
source .venv/bin/activate   # macOS / Linux
.venv\Scripts\activate      # Windows
pip install --upgrade pip
```

### 2. Install Dependencies

```bash
# Install core dependencies
pip install opencv-python numpy

# Or install all from requirements
pip install -r requirements.txt
```

### 3. Run the Demo

```bash
python main.py
```

## ðŸŽ® Controls

- **Q/ESC**: Quit application
- **I**: Toggle information panel
- **Space**: Pause/Resume video
- **R**: Reset recognition history

## ðŸ”§ Features

### Current (Dummy Implementation)
- âœ… Real-time webcam capture
- âœ… Simulated sign language recognition
- âœ… Text-to-speech output (with pyttsx3)
- âœ… Recognition history display
- âœ… FPS counter
- âœ… Confidence scores
- âœ… Mirror mode for natural interaction

### Pipeline Flow
```
Video Input (Webcam)
    â†“
Frame Processing
    â†“
Sign Language Recognition (SLR)
    â†“
Text Output
    â†“
Text-to-Speech (TTS)
    â†“
Audio Output (Speaker)
```

## ðŸ”¨ Development

### Implementing Real SLR

Replace the dummy `sign_language_recognition()` function in `slr/slr.py` with your actual model:

```python
def sign_language_recognition(video: np.ndarray) -> dict:
    # Your model implementation here
    # Example with MediaPipe:
    # 1. Extract hand landmarks
    # 2. Process sequence of landmarks
    # 3. Run through LSTM/Transformer model
    # 4. Return predicted text
    
    return {
        'text': predicted_text,
        'confidence': confidence_score,
        'detected': True,
        # ... other metadata
    }
```

### Implementing Real TTS
Replace the dummy `sign_language_recognition()` function in `tts/tts.py` with your actual implementation:

```python
def text_to_speech(txt: str) -> np.ndarray:
    # Your TTS implementation
    
    return audio_array
```

## ðŸ“Š Configuration

Modify these parameters in `main.py`:

```python
# Recognition settings
self.recognition_interval = 0.5  # Process frequency (seconds)
self.confidence_threshold = 0.6  # Min confidence for valid detection
self.speak_cooldown = 2.0       # Avoid repeating same phrase

# Video settings
self.frame_width = 640
self.frame_height = 480
```